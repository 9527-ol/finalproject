{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import json\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = psycopg2.connect(host=\"mypostgresdb.cnm9emj4w74o.us-east-2.rds.amazonaws.com\", port = 5432, database=\"project3\", user=\"rootlh\", password=\"password\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: textblob in /Users/hangli/opt/anaconda3/lib/python3.7/site-packages (0.15.3)\n",
      "Requirement already satisfied, skipping upgrade: nltk>=3.1 in /Users/hangli/opt/anaconda3/lib/python3.7/site-packages (from textblob) (3.4.5)\n",
      "Requirement already satisfied, skipping upgrade: six in /Users/hangli/opt/anaconda3/lib/python3.7/site-packages (from nltk>=3.1->textblob) (1.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U textblob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur.execute(\"\"\"SELECT * FROM posts_info\"\"\")\n",
    "# query_results = cur.fetchall()\n",
    "# query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>'https://www.youtube.com/watch?v=8IEQpfA528M  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>INFP</td>\n",
       "      <td>'It's one of my daily 'music doodles', one min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>INFP</td>\n",
       "      <td>'NO. But I have dyscalculia. :X|||I've learned...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>'288970 It's been a while, guys. Also I bleach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>INFP</td>\n",
       "      <td>'29 and still have it. Never had a girlfriend....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INTJ  'https://www.youtube.com/watch?v=8IEQpfA528M  ...\n",
       "1  INFP  'It's one of my daily 'music doodles', one min...\n",
       "2  INFP  'NO. But I have dyscalculia. :X|||I've learned...\n",
       "3  ISTP  '288970 It's been a while, guys. Also I bleach...\n",
       "4  INFP  '29 and still have it. Never had a girlfriend...."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_sql_query('select * from post_info', con=connection_string)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   type                                              posts  words_per_comment\n",
      "0  INTJ  'https://www.youtube.com/watch?v=8IEQpfA528M  ...              22.86\n",
      "1  INFP  'It's one of my daily 'music doodles', one min...              17.46\n",
      "2  INFP  'NO. But I have dyscalculia. :X|||I've learned...              13.30\n",
      "3  ISTP  '288970 It's been a while, guys. Also I bleach...              10.90\n",
      "4  INFP  '29 and still have it. Never had a girlfriend....              27.98\n"
     ]
    }
   ],
   "source": [
    "df['words_per_comment'] = df['posts'].apply(lambda x: len(x.split())/50)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   type                                              posts  words_per_comment  \\\n",
      "0  INTJ  'https://www.youtube.com/watch?v=8IEQpfA528M  ...              22.86   \n",
      "1  INFP  'It's one of my daily 'music doodles', one min...              17.46   \n",
      "2  INFP  'NO. But I have dyscalculia. :X|||I've learned...              13.30   \n",
      "3  ISTP  '288970 It's been a while, guys. Also I bleach...              10.90   \n",
      "4  INFP  '29 and still have it. Never had a girlfriend....              27.98   \n",
      "5  INFJ  'It gets to be pretty obvious the lifestyle di...              20.98   \n",
      "6  INTP  'I used to find this difficult until I realize...              23.80   \n",
      "7  INTJ  '1. ENTJs - Without fail my favorite people.  ...              33.88   \n",
      "8  ENFP  'Can I just say I'm so glad and thankful that ...              26.28   \n",
      "9  ESFP  'No I'm not, you go home!|||Farnsworth: ENTP F...              21.80   \n",
      "\n",
      "   question_per_comment  excl_per_comment  upper_case  polarity  subjectivity  \\\n",
      "0                  0.68              0.00        3.64  0.101422      0.546946   \n",
      "1                  0.30              0.12        4.68  0.067913      0.542686   \n",
      "2                  0.12              0.06        3.68  0.128141      0.579492   \n",
      "3                  0.16              0.26        2.50  0.052717      0.557769   \n",
      "4                  0.16              0.06        4.42  0.046999      0.505684   \n",
      "5                  0.18              0.02        5.44  0.161881      0.531768   \n",
      "6                  0.80              0.40        5.64  0.120509      0.571574   \n",
      "7                  0.04              0.00        7.10  0.110448      0.474402   \n",
      "8                  0.76              0.20        5.98  0.098544      0.615180   \n",
      "9                  0.18              0.02        7.54  0.101305      0.520738   \n",
      "\n",
      "   ellipsis_per_comment  \n",
      "0                  0.60  \n",
      "1                  0.34  \n",
      "2                  0.32  \n",
      "3                  0.10  \n",
      "4                  0.80  \n",
      "5                  0.38  \n",
      "6                  0.98  \n",
      "7                  0.92  \n",
      "8                  0.64  \n",
      "9                  0.42  \n"
     ]
    }
   ],
   "source": [
    "df['words_per_comment'] = df['posts'].apply(lambda x: len(x.split())/50)\n",
    "df['question_per_comment'] = df['posts'].apply(lambda x: x.count('?')/50)\n",
    "df['excl_per_comment'] = df['posts'].apply(lambda x: x.count('!')/50)\n",
    "df['upper_case'] = df['posts'].str.findall(r'[A-Z]').str.len()/50\n",
    "# df['adj'] = df['posts'].str.findall(r'[A-Z]').str.len()/50\n",
    "df[['polarity', 'subjectivity']] = df['posts'].apply(lambda Text: pd.Series(TextBlob(Text).sentiment))\n",
    "# df['emojis'] = df['posts'].str.findall(u'[\\U0001f300-\\U0001f650]|[\\u2000-\\u3000]').str.len()\n",
    "df['ellipsis_per_comment'] = df['posts'].apply(lambda x: x.count('...')/50)\n",
    "\n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>words_per_comment</th>\n",
       "      <th>question_per_comment</th>\n",
       "      <th>excl_per_comment</th>\n",
       "      <th>upper_case</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>ellipsis_per_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>'https://www.youtube.com/watch?v=8IEQpfA528M  ...</td>\n",
       "      <td>22.86</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.64</td>\n",
       "      <td>0.101422</td>\n",
       "      <td>0.546946</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>INFP</td>\n",
       "      <td>'It's one of my daily 'music doodles', one min...</td>\n",
       "      <td>17.46</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.12</td>\n",
       "      <td>4.68</td>\n",
       "      <td>0.067913</td>\n",
       "      <td>0.542686</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>INFP</td>\n",
       "      <td>'NO. But I have dyscalculia. :X|||I've learned...</td>\n",
       "      <td>13.30</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.06</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0.128141</td>\n",
       "      <td>0.579492</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ISTP</td>\n",
       "      <td>'288970 It's been a while, guys. Also I bleach...</td>\n",
       "      <td>10.90</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.052717</td>\n",
       "      <td>0.557769</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>INFP</td>\n",
       "      <td>'29 and still have it. Never had a girlfriend....</td>\n",
       "      <td>27.98</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.06</td>\n",
       "      <td>4.42</td>\n",
       "      <td>0.046999</td>\n",
       "      <td>0.505684</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8670</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>'What about when you hurt someone else?  Do yo...</td>\n",
       "      <td>16.34</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.02</td>\n",
       "      <td>4.42</td>\n",
       "      <td>0.181248</td>\n",
       "      <td>0.573210</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8671</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>'Any INFJ having a relationship with a ENFP? B...</td>\n",
       "      <td>29.80</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.28</td>\n",
       "      <td>6.32</td>\n",
       "      <td>0.189571</td>\n",
       "      <td>0.557296</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8672</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>'That's very interesting how you're in a relat...</td>\n",
       "      <td>29.10</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>4.52</td>\n",
       "      <td>0.189957</td>\n",
       "      <td>0.518341</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8673</td>\n",
       "      <td>ESTP</td>\n",
       "      <td>'I don't feel bad at all about that and I don'...</td>\n",
       "      <td>23.74</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.30</td>\n",
       "      <td>5.18</td>\n",
       "      <td>0.151486</td>\n",
       "      <td>0.527806</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8674</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Plot twist: every single one of these tests w...</td>\n",
       "      <td>27.62</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.06</td>\n",
       "      <td>4.58</td>\n",
       "      <td>0.063966</td>\n",
       "      <td>0.472431</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts  \\\n",
       "0     INTJ  'https://www.youtube.com/watch?v=8IEQpfA528M  ...   \n",
       "1     INFP  'It's one of my daily 'music doodles', one min...   \n",
       "2     INFP  'NO. But I have dyscalculia. :X|||I've learned...   \n",
       "3     ISTP  '288970 It's been a while, guys. Also I bleach...   \n",
       "4     INFP  '29 and still have it. Never had a girlfriend....   \n",
       "...    ...                                                ...   \n",
       "8670  INTJ  'What about when you hurt someone else?  Do yo...   \n",
       "8671  INFJ  'Any INFJ having a relationship with a ENFP? B...   \n",
       "8672  INFJ  'That's very interesting how you're in a relat...   \n",
       "8673  ESTP  'I don't feel bad at all about that and I don'...   \n",
       "8674  INTJ  'Plot twist: every single one of these tests w...   \n",
       "\n",
       "      words_per_comment  question_per_comment  excl_per_comment  upper_case  \\\n",
       "0                 22.86                  0.68              0.00        3.64   \n",
       "1                 17.46                  0.30              0.12        4.68   \n",
       "2                 13.30                  0.12              0.06        3.68   \n",
       "3                 10.90                  0.16              0.26        2.50   \n",
       "4                 27.98                  0.16              0.06        4.42   \n",
       "...                 ...                   ...               ...         ...   \n",
       "8670              16.34                  0.20              0.02        4.42   \n",
       "8671              29.80                  0.34              0.28        6.32   \n",
       "8672              29.10                  0.02              0.02        4.52   \n",
       "8673              23.74                  0.46              0.30        5.18   \n",
       "8674              27.62                  0.28              0.06        4.58   \n",
       "\n",
       "      polarity  subjectivity  ellipsis_per_comment  \n",
       "0     0.101422      0.546946                  0.60  \n",
       "1     0.067913      0.542686                  0.34  \n",
       "2     0.128141      0.579492                  0.32  \n",
       "3     0.052717      0.557769                  0.10  \n",
       "4     0.046999      0.505684                  0.80  \n",
       "...        ...           ...                   ...  \n",
       "8670  0.181248      0.573210                  0.50  \n",
       "8671  0.189571      0.557296                  0.90  \n",
       "8672  0.189957      0.518341                  0.74  \n",
       "8673  0.151486      0.527806                  0.72  \n",
       "8674  0.063966      0.472431                  0.70  \n",
       "\n",
       "[8675 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   type                                              posts  words_per_comment  \\\n",
      "0  INTJ  'https://www.youtube.com/watch?v=8IEQpfA528M  ...              22.86   \n",
      "1  INFP  'It's one of my daily 'music doodles', one min...              17.46   \n",
      "2  INFP  'NO. But I have dyscalculia. :X|||I've learned...              13.30   \n",
      "3  ISTP  '288970 It's been a while, guys. Also I bleach...              10.90   \n",
      "4  INFP  '29 and still have it. Never had a girlfriend....              27.98   \n",
      "5  INFJ  'It gets to be pretty obvious the lifestyle di...              20.98   \n",
      "6  INTP  'I used to find this difficult until I realize...              23.80   \n",
      "7  INTJ  '1. ENTJs - Without fail my favorite people.  ...              33.88   \n",
      "8  ENFP  'Can I just say I'm so glad and thankful that ...              26.28   \n",
      "9  ESFP  'No I'm not, you go home!|||Farnsworth: ENTP F...              21.80   \n",
      "\n",
      "   question_per_comment  excl_per_comment  upper_case  polarity  subjectivity  \\\n",
      "0                  0.68              0.00        3.64  0.101422      0.546946   \n",
      "1                  0.30              0.12        4.68  0.067913      0.542686   \n",
      "2                  0.12              0.06        3.68  0.128141      0.579492   \n",
      "3                  0.16              0.26        2.50  0.052717      0.557769   \n",
      "4                  0.16              0.06        4.42  0.046999      0.505684   \n",
      "5                  0.18              0.02        5.44  0.161881      0.531768   \n",
      "6                  0.80              0.40        5.64  0.120509      0.571574   \n",
      "7                  0.04              0.00        7.10  0.110448      0.474402   \n",
      "8                  0.76              0.20        5.98  0.098544      0.615180   \n",
      "9                  0.18              0.02        7.54  0.101305      0.520738   \n",
      "\n",
      "   ellipsis_per_comment  I-E  N-S  T-F  J-P  \n",
      "0                  0.60    0    0    0    0  \n",
      "1                  0.34    0    0    1    1  \n",
      "2                  0.32    0    0    1    1  \n",
      "3                  0.10    0    1    0    1  \n",
      "4                  0.80    0    0    1    1  \n",
      "5                  0.38    0    0    1    0  \n",
      "6                  0.98    0    0    0    1  \n",
      "7                  0.92    0    0    0    0  \n",
      "8                  0.64    1    0    1    1  \n",
      "9                  0.42    1    1    1    1  \n"
     ]
    }
   ],
   "source": [
    "map1 = {\"I\": 0, \"E\": 1}\n",
    "map2 = {\"N\": 0, \"S\": 1}\n",
    "map3 = {\"T\": 0, \"F\": 1}\n",
    "map4 = {\"J\": 0, \"P\": 1}\n",
    "df['I-E'] = df['type'].astype(str).str[0]\n",
    "df['I-E'] = df['I-E'].map(map1)\n",
    "df['N-S'] = df['type'].astype(str).str[1]\n",
    "df['N-S'] = df['N-S'].map(map2)\n",
    "df['T-F'] = df['type'].astype(str).str[2]\n",
    "df['T-F'] = df['T-F'].map(map3)\n",
    "df['J-P'] = df['type'].astype(str).str[3]\n",
    "df['J-P'] = df['J-P'].map(map4)\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8675, 7)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['type','posts','I-E','N-S','T-F','J-P'], axis=1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8675, 7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['INTJ', 'INFP', 'ISTP', 'INFJ', 'INTP', 'ENFP', 'ESFP', 'ENTP',\n",
       "       'ENFJ', 'ESTP', 'ISFP', 'ENTJ', 'ISTJ', 'ESTJ', 'ISFJ', 'ESFJ'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XX = df.drop(['type','posts','I-E'], axis=1).values\n",
    "# yy = df['I-E'].values\n",
    "\n",
    "# print(yy.shape)\n",
    "# print(XX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introvert vs. Extrovert\n",
    "y = df['I-E']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words_per_comment</th>\n",
       "      <th>question_per_comment</th>\n",
       "      <th>excl_per_comment</th>\n",
       "      <th>upper_case</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>ellipsis_per_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5495</td>\n",
       "      <td>25.74</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.02</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.193355</td>\n",
       "      <td>0.532972</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7205</td>\n",
       "      <td>30.82</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.76</td>\n",
       "      <td>0.206285</td>\n",
       "      <td>0.601249</td>\n",
       "      <td>1.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3889</td>\n",
       "      <td>30.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5.74</td>\n",
       "      <td>0.101339</td>\n",
       "      <td>0.516682</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>13.90</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.14</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.077992</td>\n",
       "      <td>0.690285</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6675</td>\n",
       "      <td>17.58</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.02</td>\n",
       "      <td>2.88</td>\n",
       "      <td>0.117476</td>\n",
       "      <td>0.608326</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3704</td>\n",
       "      <td>21.56</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.36</td>\n",
       "      <td>5.80</td>\n",
       "      <td>0.095862</td>\n",
       "      <td>0.523073</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>27.06</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.22</td>\n",
       "      <td>5.92</td>\n",
       "      <td>0.081877</td>\n",
       "      <td>0.531350</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6012</td>\n",
       "      <td>31.16</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.02</td>\n",
       "      <td>6.06</td>\n",
       "      <td>0.030651</td>\n",
       "      <td>0.505661</td>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6558</td>\n",
       "      <td>24.32</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.22</td>\n",
       "      <td>0.106238</td>\n",
       "      <td>0.503160</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7115</td>\n",
       "      <td>23.48</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.16</td>\n",
       "      <td>6.72</td>\n",
       "      <td>0.139946</td>\n",
       "      <td>0.538538</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6506 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      words_per_comment  question_per_comment  excl_per_comment  upper_case  \\\n",
       "5495              25.74                  0.28              0.02        4.50   \n",
       "7205              30.82                  0.18              0.36        6.76   \n",
       "3889              30.08                  0.08              0.08        5.74   \n",
       "94                13.90                  0.28              0.14        2.40   \n",
       "6675              17.58                  0.12              0.02        2.88   \n",
       "...                 ...                   ...               ...         ...   \n",
       "3704              21.56                  0.26              0.36        5.80   \n",
       "163               27.06                  0.26              0.22        5.92   \n",
       "6012              31.16                  0.32              0.02        6.06   \n",
       "6558              24.32                  0.18              0.00        7.22   \n",
       "7115              23.48                  0.32              0.16        6.72   \n",
       "\n",
       "      polarity  subjectivity  ellipsis_per_comment  \n",
       "5495  0.193355      0.532972                  0.62  \n",
       "7205  0.206285      0.601249                  1.16  \n",
       "3889  0.101339      0.516682                  0.72  \n",
       "94    0.077992      0.690285                  0.20  \n",
       "6675  0.117476      0.608326                  0.24  \n",
       "...        ...           ...                   ...  \n",
       "3704  0.095862      0.523073                  0.54  \n",
       "163   0.081877      0.531350                  0.72  \n",
       "6012  0.030651      0.505661                  0.74  \n",
       "6558  0.106238      0.503160                  0.60  \n",
       "7115  0.139946      0.538538                  0.70  \n",
       "\n",
       "[6506 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "8670    0\n",
       "8671    0\n",
       "8672    0\n",
       "8673    1\n",
       "8674    0\n",
       "Name: I-E, Length: 8675, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6908993 , 0.11570248, 0.005     , ..., 0.73143713, 0.5329717 ,\n",
       "        0.18674699],\n",
       "       [0.82767905, 0.07438017, 0.09      , ..., 0.7409577 , 0.6012491 ,\n",
       "        0.34939759],\n",
       "       [0.80775444, 0.03305785, 0.02      , ..., 0.66368255, 0.51668164,\n",
       "        0.21686747],\n",
       "       ...,\n",
       "       [0.8368336 , 0.1322314 , 0.005     , ..., 0.61163283, 0.50566111,\n",
       "        0.22289157],\n",
       "       [0.65266559, 0.07438017, 0.        , ..., 0.66728972, 0.50315976,\n",
       "        0.18072289],\n",
       "       [0.63004847, 0.1322314 , 0.04      , ..., 0.69210999, 0.53853771,\n",
       "        0.21084337]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=200, activation='relu', input_dim=7))\n",
    "model.add(Dense(units=200, activation='relu'))\n",
    "model.add(Dense(units=2, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 200)               1600      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 42,202\n",
      "Trainable params: 42,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "204/204 - 0s - loss: 0.5437 - accuracy: 0.7658\n",
      "Epoch 2/60\n",
      "204/204 - 0s - loss: 0.5368 - accuracy: 0.7687\n",
      "Epoch 3/60\n",
      "204/204 - 0s - loss: 0.5318 - accuracy: 0.7699\n",
      "Epoch 4/60\n",
      "204/204 - 0s - loss: 0.5298 - accuracy: 0.7704\n",
      "Epoch 5/60\n",
      "204/204 - 0s - loss: 0.5284 - accuracy: 0.7698\n",
      "Epoch 6/60\n",
      "204/204 - 0s - loss: 0.5288 - accuracy: 0.7699\n",
      "Epoch 7/60\n",
      "204/204 - 0s - loss: 0.5328 - accuracy: 0.7701\n",
      "Epoch 8/60\n",
      "204/204 - 0s - loss: 0.5309 - accuracy: 0.7691\n",
      "Epoch 9/60\n",
      "204/204 - 0s - loss: 0.5288 - accuracy: 0.7694\n",
      "Epoch 10/60\n",
      "204/204 - 0s - loss: 0.5289 - accuracy: 0.7696\n",
      "Epoch 11/60\n",
      "204/204 - 0s - loss: 0.5274 - accuracy: 0.7690\n",
      "Epoch 12/60\n",
      "204/204 - 0s - loss: 0.5303 - accuracy: 0.7701\n",
      "Epoch 13/60\n",
      "204/204 - 0s - loss: 0.5261 - accuracy: 0.7698\n",
      "Epoch 14/60\n",
      "204/204 - 0s - loss: 0.5263 - accuracy: 0.7688\n",
      "Epoch 15/60\n",
      "204/204 - 0s - loss: 0.5268 - accuracy: 0.7687\n",
      "Epoch 16/60\n",
      "204/204 - 0s - loss: 0.5255 - accuracy: 0.7694\n",
      "Epoch 17/60\n",
      "204/204 - 0s - loss: 0.5243 - accuracy: 0.7688\n",
      "Epoch 18/60\n",
      "204/204 - 0s - loss: 0.5258 - accuracy: 0.7691\n",
      "Epoch 19/60\n",
      "204/204 - 0s - loss: 0.5260 - accuracy: 0.7699\n",
      "Epoch 20/60\n",
      "204/204 - 0s - loss: 0.5243 - accuracy: 0.7687\n",
      "Epoch 21/60\n",
      "204/204 - 0s - loss: 0.5251 - accuracy: 0.7701\n",
      "Epoch 22/60\n",
      "204/204 - 0s - loss: 0.5245 - accuracy: 0.7705\n",
      "Epoch 23/60\n",
      "204/204 - 0s - loss: 0.5269 - accuracy: 0.7708\n",
      "Epoch 24/60\n",
      "204/204 - 0s - loss: 0.5274 - accuracy: 0.7694\n",
      "Epoch 25/60\n",
      "204/204 - 0s - loss: 0.5268 - accuracy: 0.7684\n",
      "Epoch 26/60\n",
      "204/204 - 0s - loss: 0.5255 - accuracy: 0.7698\n",
      "Epoch 27/60\n",
      "204/204 - 0s - loss: 0.5258 - accuracy: 0.7698\n",
      "Epoch 28/60\n",
      "204/204 - 0s - loss: 0.5245 - accuracy: 0.7694\n",
      "Epoch 29/60\n",
      "204/204 - 0s - loss: 0.5236 - accuracy: 0.7696\n",
      "Epoch 30/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.7684\n",
      "Epoch 31/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.7687\n",
      "Epoch 32/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.7687\n",
      "Epoch 33/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.7687\n",
      "Epoch 34/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.7687\n",
      "Epoch 35/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.7687\n",
      "Epoch 36/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.7687\n",
      "Epoch 37/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.7687\n",
      "Epoch 38/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.7687\n",
      "Epoch 39/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.7687\n",
      "Epoch 40/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.7687\n",
      "Epoch 41/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.7687\n",
      "Epoch 42/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.7687\n",
      "Epoch 43/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.7687\n",
      "Epoch 44/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.7687\n",
      "Epoch 45/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.7687\n",
      "Epoch 46/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.7687\n",
      "Epoch 47/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.7687\n",
      "Epoch 48/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.7687\n",
      "Epoch 49/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.7687\n",
      "Epoch 50/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.7687\n",
      "Epoch 51/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.7687\n",
      "Epoch 52/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.7687\n",
      "Epoch 53/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.7687\n",
      "Epoch 54/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.7687\n",
      "Epoch 55/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.7687\n",
      "Epoch 56/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.7687\n",
      "Epoch 57/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.7687\n",
      "Epoch 58/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.7687\n",
      "Epoch 59/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.7687\n",
      "Epoch 60/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.7687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x141152790>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 - 0s - loss: nan - accuracy: 0.7722\n",
      "Normal Neural Network - Loss: nan, Accuracy: 0.7722452878952026\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intuitive vs. Sensing\n",
    "y = df['N-S'].values\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(units=200, activation='relu', input_dim=7))\n",
    "model2.add(Dense(units=200, activation='relu'))\n",
    "model2.add(Dense(units=2, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 200)               1600      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 42,202\n",
      "Trainable params: 42,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.8624\n",
      "Epoch 2/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 3/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 4/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 5/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 6/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 7/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.8624\n",
      "Epoch 8/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.8624\n",
      "Epoch 9/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.8624\n",
      "Epoch 10/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.8624\n",
      "Epoch 11/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.8624\n",
      "Epoch 12/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.8624\n",
      "Epoch 13/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 14/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 15/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 16/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 17/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 18/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 19/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 20/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 21/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 22/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 23/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 24/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 25/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 26/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.8624\n",
      "Epoch 27/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 28/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 29/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 30/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 31/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 32/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.8624\n",
      "Epoch 33/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.8624\n",
      "Epoch 34/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 35/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.8624\n",
      "Epoch 36/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 37/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.8624\n",
      "Epoch 38/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 39/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 40/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 41/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 42/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 43/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 44/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.8624\n",
      "Epoch 45/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 46/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.8624\n",
      "Epoch 47/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 48/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 49/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 50/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 51/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.8624\n",
      "Epoch 52/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.8624\n",
      "Epoch 53/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 54/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 55/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 56/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.8624\n",
      "Epoch 57/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.8624\n",
      "Epoch 58/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.8624\n",
      "Epoch 59/60\n",
      "204/204 - 1s - loss: nan - accuracy: 0.8624\n",
      "Epoch 60/60\n",
      "204/204 - 0s - loss: nan - accuracy: 0.8624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1419db310>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 - 0s - loss: nan - accuracy: 0.8608\n",
      "Normal Neural Network - Loss: nan, Accuracy: 0.8607653379440308\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model2.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thinking vs. Feeling\n",
    "y = df['T-F'].values\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(units=200, activation='sigmoid', input_dim=7))\n",
    "model3.add(Dense(units=200, activation='sigmoid'))\n",
    "model3.add(Dense(units=2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 200)               1600      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 42,202\n",
      "Trainable params: 42,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "204/204 - 0s - loss: 0.6925 - accuracy: 0.5400\n",
      "Epoch 2/60\n",
      "204/204 - 0s - loss: 0.6902 - accuracy: 0.5418\n",
      "Epoch 3/60\n",
      "204/204 - 0s - loss: 0.6898 - accuracy: 0.5418\n",
      "Epoch 4/60\n",
      "204/204 - 0s - loss: 0.6894 - accuracy: 0.5418\n",
      "Epoch 5/60\n",
      "204/204 - 1s - loss: 0.6893 - accuracy: 0.5418\n",
      "Epoch 6/60\n",
      "204/204 - 0s - loss: 0.6879 - accuracy: 0.5418\n",
      "Epoch 7/60\n",
      "204/204 - 0s - loss: 0.6850 - accuracy: 0.5453\n",
      "Epoch 8/60\n",
      "204/204 - 1s - loss: 0.6828 - accuracy: 0.5427\n",
      "Epoch 9/60\n",
      "204/204 - 1s - loss: 0.6712 - accuracy: 0.5629\n",
      "Epoch 10/60\n",
      "204/204 - 0s - loss: 0.6651 - accuracy: 0.5882\n",
      "Epoch 11/60\n",
      "204/204 - 1s - loss: 0.6636 - accuracy: 0.5921\n",
      "Epoch 12/60\n",
      "204/204 - 1s - loss: 0.6632 - accuracy: 0.5899\n",
      "Epoch 13/60\n",
      "204/204 - 1s - loss: 0.6610 - accuracy: 0.6005\n",
      "Epoch 14/60\n",
      "204/204 - 1s - loss: 0.6619 - accuracy: 0.5931\n",
      "Epoch 15/60\n",
      "204/204 - 0s - loss: 0.6623 - accuracy: 0.5956\n",
      "Epoch 16/60\n",
      "204/204 - 0s - loss: 0.6596 - accuracy: 0.5988\n",
      "Epoch 17/60\n",
      "204/204 - 1s - loss: 0.6583 - accuracy: 0.6041\n",
      "Epoch 18/60\n",
      "204/204 - 0s - loss: 0.6572 - accuracy: 0.6068\n",
      "Epoch 19/60\n",
      "204/204 - 1s - loss: 0.6558 - accuracy: 0.6133\n",
      "Epoch 20/60\n",
      "204/204 - 0s - loss: 0.6588 - accuracy: 0.5985\n",
      "Epoch 21/60\n",
      "204/204 - 0s - loss: 0.6560 - accuracy: 0.6085\n",
      "Epoch 22/60\n",
      "204/204 - 0s - loss: 0.6524 - accuracy: 0.6140\n",
      "Epoch 23/60\n",
      "204/204 - 0s - loss: 0.6587 - accuracy: 0.6033\n",
      "Epoch 24/60\n",
      "204/204 - 0s - loss: 0.6535 - accuracy: 0.6074\n",
      "Epoch 25/60\n",
      "204/204 - 0s - loss: 0.6520 - accuracy: 0.6128\n",
      "Epoch 26/60\n",
      "204/204 - 1s - loss: 0.6523 - accuracy: 0.6122\n",
      "Epoch 27/60\n",
      "204/204 - 1s - loss: 0.6527 - accuracy: 0.6187\n",
      "Epoch 28/60\n",
      "204/204 - 1s - loss: 0.6508 - accuracy: 0.6159\n",
      "Epoch 29/60\n",
      "204/204 - 0s - loss: 0.6529 - accuracy: 0.6079\n",
      "Epoch 30/60\n",
      "204/204 - 0s - loss: 0.6490 - accuracy: 0.6267\n",
      "Epoch 31/60\n",
      "204/204 - 0s - loss: 0.6489 - accuracy: 0.6168\n",
      "Epoch 32/60\n",
      "204/204 - 1s - loss: 0.6516 - accuracy: 0.6160\n",
      "Epoch 33/60\n",
      "204/204 - 1s - loss: 0.6504 - accuracy: 0.6139\n",
      "Epoch 34/60\n",
      "204/204 - 0s - loss: 0.6497 - accuracy: 0.6168\n",
      "Epoch 35/60\n",
      "204/204 - 1s - loss: 0.6484 - accuracy: 0.6190\n",
      "Epoch 36/60\n",
      "204/204 - 0s - loss: 0.6492 - accuracy: 0.6220\n",
      "Epoch 37/60\n",
      "204/204 - 1s - loss: 0.6493 - accuracy: 0.6119\n",
      "Epoch 38/60\n",
      "204/204 - 1s - loss: 0.6478 - accuracy: 0.6251\n",
      "Epoch 39/60\n",
      "204/204 - 1s - loss: 0.6527 - accuracy: 0.6164\n",
      "Epoch 40/60\n",
      "204/204 - 1s - loss: 0.6472 - accuracy: 0.6257\n",
      "Epoch 41/60\n",
      "204/204 - 0s - loss: 0.6464 - accuracy: 0.6302\n",
      "Epoch 42/60\n",
      "204/204 - 1s - loss: 0.6465 - accuracy: 0.6245\n",
      "Epoch 43/60\n",
      "204/204 - 0s - loss: 0.6473 - accuracy: 0.6237\n",
      "Epoch 44/60\n",
      "204/204 - 0s - loss: 0.6485 - accuracy: 0.6205\n",
      "Epoch 45/60\n",
      "204/204 - 0s - loss: 0.6462 - accuracy: 0.6208\n",
      "Epoch 46/60\n",
      "204/204 - 0s - loss: 0.6459 - accuracy: 0.6262\n",
      "Epoch 47/60\n",
      "204/204 - 0s - loss: 0.6463 - accuracy: 0.6233\n",
      "Epoch 48/60\n",
      "204/204 - 1s - loss: 0.6467 - accuracy: 0.6213\n",
      "Epoch 49/60\n",
      "204/204 - 1s - loss: 0.6481 - accuracy: 0.6210\n",
      "Epoch 50/60\n",
      "204/204 - 1s - loss: 0.6442 - accuracy: 0.6245\n",
      "Epoch 51/60\n",
      "204/204 - 1s - loss: 0.6441 - accuracy: 0.6288\n",
      "Epoch 52/60\n",
      "204/204 - 1s - loss: 0.6478 - accuracy: 0.6217\n",
      "Epoch 53/60\n",
      "204/204 - 1s - loss: 0.6447 - accuracy: 0.6237\n",
      "Epoch 54/60\n",
      "204/204 - 1s - loss: 0.6433 - accuracy: 0.6245\n",
      "Epoch 55/60\n",
      "204/204 - 1s - loss: 0.6442 - accuracy: 0.6274\n",
      "Epoch 56/60\n",
      "204/204 - 1s - loss: 0.6436 - accuracy: 0.6279\n",
      "Epoch 57/60\n",
      "204/204 - 0s - loss: 0.6419 - accuracy: 0.6303\n",
      "Epoch 58/60\n",
      "204/204 - 0s - loss: 0.6456 - accuracy: 0.6250\n",
      "Epoch 59/60\n",
      "204/204 - 0s - loss: 0.6419 - accuracy: 0.6322\n",
      "Epoch 60/60\n",
      "204/204 - 0s - loss: 0.6427 - accuracy: 0.6288\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x141a62910>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 - 0s - loss: 0.6364 - accuracy: 0.6445\n",
      "Normal Neural Network - Loss: 0.6363771557807922, Accuracy: 0.6445366740226746\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model3.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Judging vs. Perceiving\n",
    "y = df['J-P'].values\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Dense(units=200, activation='sigmoid', input_dim=7))\n",
    "model4.add(Dense(units=200, activation='sigmoid'))\n",
    "model4.add(Dense(units=2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 200)               1600      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 42,202\n",
      "Trainable params: 42,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "204/204 - 1s - loss: 0.6740 - accuracy: 0.6027\n",
      "Epoch 2/60\n",
      "204/204 - 1s - loss: 0.6746 - accuracy: 0.6030\n",
      "Epoch 3/60\n",
      "204/204 - 0s - loss: 0.6743 - accuracy: 0.6030\n",
      "Epoch 4/60\n",
      "204/204 - 1s - loss: 0.6742 - accuracy: 0.6030\n",
      "Epoch 5/60\n",
      "204/204 - 0s - loss: 0.6731 - accuracy: 0.6030\n",
      "Epoch 6/60\n",
      "204/204 - 0s - loss: 0.6744 - accuracy: 0.6030\n",
      "Epoch 7/60\n",
      "204/204 - 1s - loss: 0.6730 - accuracy: 0.6030\n",
      "Epoch 8/60\n",
      "204/204 - 1s - loss: 0.6727 - accuracy: 0.6030\n",
      "Epoch 9/60\n",
      "204/204 - 1s - loss: 0.6735 - accuracy: 0.6030\n",
      "Epoch 10/60\n",
      "204/204 - 1s - loss: 0.6726 - accuracy: 0.6030\n",
      "Epoch 11/60\n",
      "204/204 - 0s - loss: 0.6725 - accuracy: 0.6030\n",
      "Epoch 12/60\n",
      "204/204 - 0s - loss: 0.6726 - accuracy: 0.6030\n",
      "Epoch 13/60\n",
      "204/204 - 1s - loss: 0.6722 - accuracy: 0.6030\n",
      "Epoch 14/60\n",
      "204/204 - 1s - loss: 0.6718 - accuracy: 0.6030\n",
      "Epoch 15/60\n",
      "204/204 - 0s - loss: 0.6732 - accuracy: 0.6030\n",
      "Epoch 16/60\n",
      "204/204 - 1s - loss: 0.6721 - accuracy: 0.6030\n",
      "Epoch 17/60\n",
      "204/204 - 1s - loss: 0.6722 - accuracy: 0.6030\n",
      "Epoch 18/60\n",
      "204/204 - 0s - loss: 0.6721 - accuracy: 0.6030\n",
      "Epoch 19/60\n",
      "204/204 - 0s - loss: 0.6726 - accuracy: 0.6030\n",
      "Epoch 20/60\n",
      "204/204 - 0s - loss: 0.6718 - accuracy: 0.6030\n",
      "Epoch 21/60\n",
      "204/204 - 1s - loss: 0.6722 - accuracy: 0.6030\n",
      "Epoch 22/60\n",
      "204/204 - 0s - loss: 0.6720 - accuracy: 0.6030\n",
      "Epoch 23/60\n",
      "204/204 - 0s - loss: 0.6722 - accuracy: 0.6030\n",
      "Epoch 24/60\n",
      "204/204 - 0s - loss: 0.6725 - accuracy: 0.6030\n",
      "Epoch 25/60\n",
      "204/204 - 0s - loss: 0.6725 - accuracy: 0.6030\n",
      "Epoch 26/60\n",
      "204/204 - 0s - loss: 0.6725 - accuracy: 0.6030\n",
      "Epoch 27/60\n",
      "204/204 - 0s - loss: 0.6720 - accuracy: 0.6030\n",
      "Epoch 28/60\n",
      "204/204 - 0s - loss: 0.6718 - accuracy: 0.6030\n",
      "Epoch 29/60\n",
      "204/204 - 0s - loss: 0.6719 - accuracy: 0.6030\n",
      "Epoch 30/60\n",
      "204/204 - 0s - loss: 0.6723 - accuracy: 0.6030\n",
      "Epoch 31/60\n",
      "204/204 - 0s - loss: 0.6719 - accuracy: 0.6030\n",
      "Epoch 32/60\n",
      "204/204 - 0s - loss: 0.6719 - accuracy: 0.6030\n",
      "Epoch 33/60\n",
      "204/204 - 0s - loss: 0.6723 - accuracy: 0.6030\n",
      "Epoch 34/60\n",
      "204/204 - 0s - loss: 0.6717 - accuracy: 0.6030\n",
      "Epoch 35/60\n",
      "204/204 - 1s - loss: 0.6717 - accuracy: 0.6030\n",
      "Epoch 36/60\n",
      "204/204 - 0s - loss: 0.6718 - accuracy: 0.6030\n",
      "Epoch 37/60\n",
      "204/204 - 1s - loss: 0.6717 - accuracy: 0.6030\n",
      "Epoch 38/60\n",
      "204/204 - 1s - loss: 0.6718 - accuracy: 0.6030\n",
      "Epoch 39/60\n",
      "204/204 - 0s - loss: 0.6720 - accuracy: 0.6030\n",
      "Epoch 40/60\n",
      "204/204 - 1s - loss: 0.6716 - accuracy: 0.6030\n",
      "Epoch 41/60\n",
      "204/204 - 0s - loss: 0.6716 - accuracy: 0.6030\n",
      "Epoch 42/60\n",
      "204/204 - 1s - loss: 0.6721 - accuracy: 0.6030\n",
      "Epoch 43/60\n",
      "204/204 - 1s - loss: 0.6718 - accuracy: 0.6030\n",
      "Epoch 44/60\n",
      "204/204 - 1s - loss: 0.6716 - accuracy: 0.6030\n",
      "Epoch 45/60\n",
      "204/204 - 1s - loss: 0.6719 - accuracy: 0.6030\n",
      "Epoch 46/60\n",
      "204/204 - 1s - loss: 0.6713 - accuracy: 0.6030\n",
      "Epoch 47/60\n",
      "204/204 - 1s - loss: 0.6717 - accuracy: 0.6030\n",
      "Epoch 48/60\n",
      "204/204 - 0s - loss: 0.6713 - accuracy: 0.6030\n",
      "Epoch 49/60\n",
      "204/204 - 0s - loss: 0.6711 - accuracy: 0.6030\n",
      "Epoch 50/60\n",
      "204/204 - 0s - loss: 0.6717 - accuracy: 0.6030\n",
      "Epoch 51/60\n",
      "204/204 - 1s - loss: 0.6712 - accuracy: 0.6030\n",
      "Epoch 52/60\n",
      "204/204 - 1s - loss: 0.6713 - accuracy: 0.6030\n",
      "Epoch 53/60\n",
      "204/204 - 1s - loss: 0.6712 - accuracy: 0.6030\n",
      "Epoch 54/60\n",
      "204/204 - 1s - loss: 0.6713 - accuracy: 0.6030\n",
      "Epoch 55/60\n",
      "204/204 - 1s - loss: 0.6709 - accuracy: 0.6030\n",
      "Epoch 56/60\n",
      "204/204 - 1s - loss: 0.6709 - accuracy: 0.6030\n",
      "Epoch 57/60\n",
      "204/204 - 1s - loss: 0.6710 - accuracy: 0.6030\n",
      "Epoch 58/60\n",
      "204/204 - 1s - loss: 0.6715 - accuracy: 0.6030\n",
      "Epoch 59/60\n",
      "204/204 - 1s - loss: 0.6709 - accuracy: 0.6030\n",
      "Epoch 60/60\n",
      "204/204 - 1s - loss: 0.6715 - accuracy: 0.6030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x141a1d4d0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 - 0s - loss: 0.6684 - accuracy: 0.6077\n",
      "Normal Neural Network - Loss: 0.6683854460716248, Accuracy: 0.6076533198356628\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model4.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall\n",
    "y = df['type'].values\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(Dense(units=200, activation='sigmoid', input_dim=7))\n",
    "model5.add(Dense(units=200, activation='sigmoid'))\n",
    "model5.add(Dense(units=16, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 200)               1600      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                3216      \n",
      "=================================================================\n",
      "Total params: 45,016\n",
      "Trainable params: 45,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model5.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "204/204 - 1s - loss: 2.3127 - accuracy: 0.2049\n",
      "Epoch 2/60\n",
      "204/204 - 1s - loss: 2.2924 - accuracy: 0.2073\n",
      "Epoch 3/60\n",
      "204/204 - 1s - loss: 2.2901 - accuracy: 0.2073\n",
      "Epoch 4/60\n",
      "204/204 - 1s - loss: 2.2889 - accuracy: 0.2073\n",
      "Epoch 5/60\n",
      "204/204 - 1s - loss: 2.2880 - accuracy: 0.2073\n",
      "Epoch 6/60\n",
      "204/204 - 1s - loss: 2.2870 - accuracy: 0.2073\n",
      "Epoch 7/60\n",
      "204/204 - 1s - loss: 2.2860 - accuracy: 0.2073\n",
      "Epoch 8/60\n",
      "204/204 - 1s - loss: 2.2841 - accuracy: 0.2073\n",
      "Epoch 9/60\n",
      "204/204 - 1s - loss: 2.2829 - accuracy: 0.2073\n",
      "Epoch 10/60\n",
      "204/204 - 1s - loss: 2.2805 - accuracy: 0.2073\n",
      "Epoch 11/60\n",
      "204/204 - 1s - loss: 2.2789 - accuracy: 0.2073\n",
      "Epoch 12/60\n",
      "204/204 - 1s - loss: 2.2737 - accuracy: 0.2073\n",
      "Epoch 13/60\n",
      "204/204 - 1s - loss: 2.2665 - accuracy: 0.2073\n",
      "Epoch 14/60\n",
      "204/204 - 1s - loss: 2.2568 - accuracy: 0.2073\n",
      "Epoch 15/60\n",
      "204/204 - 1s - loss: 2.2497 - accuracy: 0.2080\n",
      "Epoch 16/60\n",
      "204/204 - 1s - loss: 2.2447 - accuracy: 0.2077\n",
      "Epoch 17/60\n",
      "204/204 - 1s - loss: 2.2421 - accuracy: 0.2100\n",
      "Epoch 18/60\n",
      "204/204 - 1s - loss: 2.2403 - accuracy: 0.2163\n",
      "Epoch 19/60\n",
      "204/204 - 1s - loss: 2.2378 - accuracy: 0.2138\n",
      "Epoch 20/60\n",
      "204/204 - 1s - loss: 2.2356 - accuracy: 0.2196\n",
      "Epoch 21/60\n",
      "204/204 - 1s - loss: 2.2372 - accuracy: 0.2146\n",
      "Epoch 22/60\n",
      "204/204 - 1s - loss: 2.2355 - accuracy: 0.2201\n",
      "Epoch 23/60\n",
      "204/204 - 0s - loss: 2.2345 - accuracy: 0.2212\n",
      "Epoch 24/60\n",
      "204/204 - 0s - loss: 2.2327 - accuracy: 0.2198\n",
      "Epoch 25/60\n",
      "204/204 - 1s - loss: 2.2325 - accuracy: 0.2196\n",
      "Epoch 26/60\n",
      "204/204 - 1s - loss: 2.2295 - accuracy: 0.2232\n",
      "Epoch 27/60\n",
      "204/204 - 1s - loss: 2.2308 - accuracy: 0.2236\n",
      "Epoch 28/60\n",
      "204/204 - 1s - loss: 2.2295 - accuracy: 0.2269\n",
      "Epoch 29/60\n",
      "204/204 - 1s - loss: 2.2303 - accuracy: 0.2241\n",
      "Epoch 30/60\n",
      "204/204 - 1s - loss: 2.2292 - accuracy: 0.2269\n",
      "Epoch 31/60\n",
      "204/204 - 0s - loss: 2.2289 - accuracy: 0.2218\n",
      "Epoch 32/60\n",
      "204/204 - 0s - loss: 2.2274 - accuracy: 0.2283\n",
      "Epoch 33/60\n",
      "204/204 - 0s - loss: 2.2281 - accuracy: 0.2258\n",
      "Epoch 34/60\n",
      "204/204 - 0s - loss: 2.2279 - accuracy: 0.2263\n",
      "Epoch 35/60\n",
      "204/204 - 0s - loss: 2.2288 - accuracy: 0.2256\n",
      "Epoch 36/60\n",
      "204/204 - 0s - loss: 2.2279 - accuracy: 0.2276\n",
      "Epoch 37/60\n",
      "204/204 - 0s - loss: 2.2261 - accuracy: 0.2267\n",
      "Epoch 38/60\n",
      "204/204 - 0s - loss: 2.2261 - accuracy: 0.2286\n",
      "Epoch 39/60\n",
      "204/204 - 0s - loss: 2.2245 - accuracy: 0.2259\n",
      "Epoch 40/60\n",
      "204/204 - 0s - loss: 2.2240 - accuracy: 0.2270\n",
      "Epoch 41/60\n",
      "204/204 - 0s - loss: 2.2241 - accuracy: 0.2261\n",
      "Epoch 42/60\n",
      "204/204 - 1s - loss: 2.2238 - accuracy: 0.2249\n",
      "Epoch 43/60\n",
      "204/204 - 1s - loss: 2.2243 - accuracy: 0.2289\n",
      "Epoch 44/60\n",
      "204/204 - 1s - loss: 2.2218 - accuracy: 0.2304\n",
      "Epoch 45/60\n",
      "204/204 - 0s - loss: 2.2232 - accuracy: 0.2269\n",
      "Epoch 46/60\n",
      "204/204 - 0s - loss: 2.2237 - accuracy: 0.2292\n",
      "Epoch 47/60\n",
      "204/204 - 1s - loss: 2.2209 - accuracy: 0.2276\n",
      "Epoch 48/60\n",
      "204/204 - 1s - loss: 2.2226 - accuracy: 0.2273\n",
      "Epoch 49/60\n",
      "204/204 - 0s - loss: 2.2215 - accuracy: 0.2286\n",
      "Epoch 50/60\n",
      "204/204 - 1s - loss: 2.2211 - accuracy: 0.2329\n",
      "Epoch 51/60\n",
      "204/204 - 1s - loss: 2.2207 - accuracy: 0.2275\n",
      "Epoch 52/60\n",
      "204/204 - 1s - loss: 2.2204 - accuracy: 0.2276\n",
      "Epoch 53/60\n",
      "204/204 - 1s - loss: 2.2192 - accuracy: 0.2327\n",
      "Epoch 54/60\n",
      "204/204 - 1s - loss: 2.2197 - accuracy: 0.2298\n",
      "Epoch 55/60\n",
      "204/204 - 1s - loss: 2.2187 - accuracy: 0.2324\n",
      "Epoch 56/60\n",
      "204/204 - 1s - loss: 2.2187 - accuracy: 0.2290\n",
      "Epoch 57/60\n",
      "204/204 - 1s - loss: 2.2170 - accuracy: 0.2335\n",
      "Epoch 58/60\n",
      "204/204 - 1s - loss: 2.2157 - accuracy: 0.2353\n",
      "Epoch 59/60\n",
      "204/204 - 1s - loss: 2.2172 - accuracy: 0.2349\n",
      "Epoch 60/60\n",
      "204/204 - 1s - loss: 2.2147 - accuracy: 0.2353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x142133fd0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 - 0s - loss: 2.2135 - accuracy: 0.2411\n",
      "Normal Neural Network - Loss: 2.2134501934051514, Accuracy: 0.2411249428987503\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model5.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
